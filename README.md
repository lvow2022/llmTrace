# LLM Trace - OpenAIè°ƒç”¨è¿½è¸ªç³»ç»Ÿ

ä¸€ä¸ªç®€æ´çš„OpenAI APIè°ƒç”¨è¿½è¸ªå·¥å…·ï¼Œä¸“ä¸ºå¼€å‘äººå‘˜è°ƒè¯•LLMåº”ç”¨è€Œè®¾è®¡ã€‚æ”¯æŒå®æ—¶æŸ¥çœ‹è°ƒç”¨è®°å½•ã€å¯¹è¯è½®æ¬¡ç®¡ç†å’Œè¯·æ±‚é‡æ”¾åŠŸèƒ½ã€‚

## ğŸ¯ æ ¸å¿ƒåŠŸèƒ½

- **åŸ‹ç‚¹è¿½è¸ª**: ç”¨æˆ·ä»£ç ä¸­å¼‚æ­¥ä¸ŠæŠ¥LLMè°ƒç”¨æ•°æ®
- **å®æ—¶æŸ¥çœ‹**: å‰ç«¯å®šæ—¶è½®è¯¢æ˜¾ç¤ºæœ€æ–°è°ƒç”¨è®°å½•
- **å¯¹è¯è¿½è¸ª**: æŒ‰è½®æ¬¡ç»„ç»‡å’Œç®¡ç†å¯¹è¯è®°å½•
- **è¯·æ±‚é‡æ”¾**: ä¿®æ”¹è¯·æ±‚å†…å®¹åé‡æ–°æ‰§è¡Œæµ‹è¯•
- **ç™½ç›’è°ƒè¯•**: å®Œå…¨é€æ˜çš„è¯·æ±‚/å“åº”æ•°æ®ï¼Œå‘Šåˆ«é»‘ç›’è°ƒè¯•

## ğŸ—ï¸ ç³»ç»Ÿæ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ç”¨æˆ·çš„åº”ç”¨ä»£ç                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚   Agent     â”‚  â”‚   LLMè°ƒç”¨   â”‚  â”‚   åŸ‹ç‚¹ä»£ç   â”‚        â”‚
â”‚  â”‚   é€»è¾‘      â”‚  â”‚   (OpenAI)  â”‚  â”‚  (å¼‚æ­¥ä¸ŠæŠ¥) â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    LLM Trace æœåŠ¡                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚   HTTP API  â”‚  â”‚  æ•°æ®å­˜å‚¨   â”‚  â”‚  å‰ç«¯æœåŠ¡   â”‚        â”‚
â”‚  â”‚  (æ¥æ”¶æ•°æ®) â”‚  â”‚  (SQLite)   â”‚  â”‚  (æŸ¥çœ‹æ•°æ®) â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“Š æ•°æ®æ¨¡å‹

### åŸ‹ç‚¹æ•°æ®ç»“æ„
```go
type TraceRequest struct {
    SessionID    string      `json:"session_id"`
    TurnNumber   int         `json:"turn_number"`
    Request      interface{} `json:"request"`      // å®Œæ•´è¯·æ±‚æ•°æ®
    Response     interface{} `json:"response"`     // å®Œæ•´å“åº”æ•°æ®
    Status       string      `json:"status"`       // success/error/pending
    ErrorMessage string      `json:"error_message"`
    Metadata     interface{} `json:"metadata"`     // è‡ªå®šä¹‰å…ƒæ•°æ®
}
```

### æ•°æ®åº“æ¨¡å‹
```go
// å¯¹è¯ä¼šè¯
type Session struct {
    ID        string    `json:"id"`
    Name      string    `json:"name"`      // è‡ªåŠ¨ç”Ÿæˆï¼šå¯¹è¯-æ—¶é—´
    CreatedAt time.Time `json:"created_at"`
}

// è°ƒç”¨è®°å½•
type Record struct {
    ID          string    `json:"id"`
    SessionID   string    `json:"session_id"`
    TurnNumber  int       `json:"turn_number"`  // å¯¹è¯è½®æ¬¡
    Request     string    `json:"request"`      // å®Œæ•´è¯·æ±‚JSON
    Response    string    `json:"response"`     // å®Œæ•´å“åº”JSON
    Status      string    `json:"status"`       // success/error
    ErrorMsg    string    `json:"error_msg"`
    Metadata    string    `json:"metadata"`     // å…ƒæ•°æ®JSON
    CreatedAt   time.Time `json:"created_at"`
}
```

## ğŸ”Œ APIæ¥å£

### åŸ‹ç‚¹æ¥å£
```bash
# ä¸ŠæŠ¥LLMè°ƒç”¨æ•°æ®
POST /api/trace
Content-Type: application/json

{
  "session_id": "session_123",
  "turn_number": 1,
  "request": {
    "model": "gpt-3.5-turbo",
    "messages": [...],
    "temperature": 0.7
  },
  "response": {
    "id": "chatcmpl-123",
    "choices": [...],
    "usage": {...}
  },
  "status": "success",
  "error_message": "",
  "metadata": {
    "user_id": "user_123",
    "agent_name": "my_agent"
  }
}
```

### æŸ¥è¯¢æ¥å£
```bash
# è·å–ä¼šè¯åˆ—è¡¨
GET /api/sessions?page=1&size=20

# è·å–ä¼šè¯çš„è°ƒç”¨è®°å½•
GET /api/sessions/:id/records?page=1&size=50

# é‡æ”¾è¯·æ±‚
POST /api/records/:id/replay
Body: { "request": "ä¿®æ”¹åçš„è¯·æ±‚JSON" }

# åˆ é™¤è®°å½•
DELETE /api/records/:id
```

## ğŸ“ é¡¹ç›®ç»“æ„

```
llmTrace/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.go              # ä¸»ç¨‹åºå…¥å£
â”‚   â”œâ”€â”€ models.go            # æ•°æ®æ¨¡å‹
â”‚   â”œâ”€â”€ database.go          # æ•°æ®åº“æ“ä½œ
â”‚   â”œâ”€â”€ handlers.go          # HTTPå¤„ç†å™¨
â”‚   â”œâ”€â”€ config.go            # é…ç½®ç®¡ç†
â”‚   â”œâ”€â”€ go.mod               # ä¾èµ–ç®¡ç†
â”‚   â”œâ”€â”€ start.sh             # å¯åŠ¨è„šæœ¬
â”‚   â””â”€â”€ client_example.py    # å®¢æˆ·ç«¯ç¤ºä¾‹
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ App.tsx          # ä¸»åº”ç”¨
â”‚   â”‚   â”œâ”€â”€ components/      # ç»„ä»¶
â”‚   â”‚   â””â”€â”€ services/        # APIè°ƒç”¨
â”‚   â””â”€â”€ package.json
â””â”€â”€ README.md
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. å¯åŠ¨åç«¯æœåŠ¡
```bash
cd backend

# è®¾ç½®ç¯å¢ƒå˜é‡
export OPENAI_API_KEY="your-openai-api-key"
export SERVER_PORT="8080"

# å¯åŠ¨æœåŠ¡
./start.sh
# æˆ–è€…ç›´æ¥è¿è¡Œ
go run .
```

### 2. å¯åŠ¨å‰ç«¯
```bash
cd frontend
npm install
npm start
```

### 3. é›†æˆåˆ°ä½ çš„ä»£ç 
```go
// Goç¤ºä¾‹ - ç®€å•é›†æˆ
package main

import (
    "bytes"
    "encoding/json"
    "net/http"
    "time"
)

// TraceRequest åŸ‹ç‚¹è¯·æ±‚ç»“æ„
type TraceRequest struct {
    SessionID    string      `json:"session_id"`
    TurnNumber   int         `json:"turn_number"`
    Request      interface{} `json:"request"`
    Response     interface{} `json:"response"`
    Status       string      `json:"status"`
    ErrorMessage string      `json:"error_message"`
}

// traceLLMCall åŸ‹ç‚¹LLMè°ƒç”¨
func traceLLMCall(sessionID string, turnNumber int, request, response interface{}, status string) {
    traceData := TraceRequest{
        SessionID:  sessionID,
        TurnNumber: turnNumber,
        Request:    request,
        Response:   response,
        Status:     status,
    }
    
    jsonData, err := json.Marshal(traceData)
    if err != nil {
        return
    }
    
    // å¼‚æ­¥å‘é€åŸ‹ç‚¹æ•°æ®
    go func() {
        http.Post("http://localhost:8080/api/trace", "application/json", bytes.NewBuffer(jsonData))
    }()
}

// åœ¨ä½ çš„LLMè°ƒç”¨ä»£ç ä¸­æ·»åŠ åŸ‹ç‚¹
func callLLM(messages []map[string]string) (interface{}, error) {
    sessionID := "my_session_123"
    turnNumber := 1
    
    request := map[string]interface{}{
        "model":    "gpt-3.5-turbo",
        "messages": messages,
    }
    
    // åŸ‹ç‚¹è¯·æ±‚
    traceLLMCall(sessionID, turnNumber, request, nil, "pending")
    
    // æ‰§è¡ŒåŸå§‹è°ƒç”¨
    response, err := openaiClient.CreateChatCompletion(messages)
    if err != nil {
        // åŸ‹ç‚¹é”™è¯¯
        traceLLMCall(sessionID, turnNumber, request, nil, "error")
        return nil, err
    }
    
    // åŸ‹ç‚¹å“åº”
    traceLLMCall(sessionID, turnNumber, request, response, "success")
    
    return response, nil
}
```

```python
# Pythonç¤ºä¾‹ - ç®€å•é›†æˆ
import requests

def trace_llm_call(session_id, turn_number, request, response, status="success"):
    trace_data = {
        "session_id": session_id,
        "turn_number": turn_number,
        "request": request,
        "response": response,
        "status": status
    }
    
    try:
        requests.post("http://localhost:8080/api/trace", json=trace_data)
    except:
        # åŸ‹ç‚¹å¤±è´¥ä¸å½±å“ä¸»æµç¨‹
        pass

# åœ¨ä½ çš„LLMè°ƒç”¨ä»£ç ä¸­æ·»åŠ åŸ‹ç‚¹
def call_llm(messages):
    session_id = "my_session_123"
    turn_number = 1
    
    # åŸ‹ç‚¹è¯·æ±‚
    trace_llm_call(session_id, turn_number, {"messages": messages}, None, "pending")
    
    # æ‰§è¡ŒåŸå§‹è°ƒç”¨
    response = openai.chat.completions.create(messages=messages)
    
    # åŸ‹ç‚¹å“åº”
    trace_llm_call(session_id, turn_number, {"messages": messages}, response.model_dump(), "success")
    
    return response
```

### 4. å¼€å§‹è°ƒè¯•
- æ‰“å¼€å‰ç«¯ç•Œé¢ï¼šhttp://localhost:3000
- è¿è¡Œä½ çš„åº”ç”¨ï¼Œæ‰€æœ‰åŸ‹ç‚¹çš„LLMè°ƒç”¨éƒ½ä¼šæ˜¾ç¤º
- å‰ç«¯æ¯2ç§’è‡ªåŠ¨åˆ·æ–°æ˜¾ç¤ºæœ€æ–°è®°å½•
- é€‰æ‹©ä»»æ„è½®æ¬¡è¿›è¡Œé‡æ”¾æµ‹è¯•

## ğŸ”„ å·¥ä½œæµç¨‹

### åŸ‹ç‚¹æ•°æ®æµç¨‹
```
1. ç”¨æˆ·ä»£ç è°ƒç”¨LLM â†’ è·å–è¯·æ±‚å’Œå“åº”
2. æ„é€ åŸ‹ç‚¹æ•°æ® â†’ åŒ…å«å®Œæ•´ä¿¡æ¯
3. å¼‚æ­¥å‘é€åˆ°TraceæœåŠ¡ â†’ POST /api/trace
4. æœåŠ¡ä¿å­˜æ•°æ® â†’ å­˜å‚¨åˆ°SQLite
5. è¿”å›ç¡®è®¤ â†’ ç”¨æˆ·ä»£ç ç»§ç»­æ‰§è¡Œ
```

### ä¼šè¯ç®¡ç†æµç¨‹
```
1. åŸ‹ç‚¹æ•°æ®åŒ…å«session_id â†’ ç”¨æˆ·æŒ‡å®šæˆ–è‡ªåŠ¨ç”Ÿæˆ
2. æœåŠ¡æŸ¥æ‰¾ä¼šè¯ â†’ å­˜åœ¨åˆ™å…³è”ï¼Œä¸å­˜åœ¨åˆ™åˆ›å»º
3. è½®æ¬¡ç®¡ç† â†’ åŸºäºsession_idè‡ªåŠ¨é€’å¢
4. æ•°æ®å­˜å‚¨ â†’ ä¿å­˜å®Œæ•´è®°å½•
```

### é‡æ”¾æµç¨‹
```
1. å‰ç«¯é€‰æ‹©è®°å½• â†’ è·å–åŸå§‹æ•°æ®
2. ä¿®æ”¹è¯·æ±‚å†…å®¹ â†’ ç”¨æˆ·ç¼–è¾‘
3. å‘é€é‡æ”¾è¯·æ±‚ â†’ POST /api/records/:id/replay
4. æœåŠ¡æ‰§è¡Œè°ƒç”¨ â†’ è°ƒç”¨OpenAI API
5. ä¿å­˜æ–°è®°å½• â†’ å­˜å‚¨ç»“æœ
6. è¿”å›å“åº” â†’ å‰ç«¯æ˜¾ç¤º
```

## ğŸ› ï¸ æŠ€æœ¯æ ˆ

- **åç«¯**: Go + Gin + SQLite
- **å‰ç«¯**: React + TypeScript + Axios
- **å­˜å‚¨**: SQLiteï¼ˆå•æ–‡ä»¶ï¼‰
- **é€šä¿¡**: REST API + å®šæ—¶è½®è¯¢

## âœ¨ æ ¸å¿ƒä¼˜åŠ¿

- **æç®€æ¶æ„**: 5ä¸ªæ ¸å¿ƒæ–‡ä»¶ï¼Œé›¶å¤æ‚æ€§
- **é›¶ä¾µå…¥æ€§**: åªéœ€æ·»åŠ å‡ è¡ŒåŸ‹ç‚¹ä»£ç ï¼Œä¸å½±å“ç°æœ‰é€»è¾‘
- **å¼‚æ­¥æ‰§è¡Œ**: åŸ‹ç‚¹å¤±è´¥ä¸å½±å“ä¸»æµç¨‹
- **å¿«é€Ÿé›†æˆ**: ä»»ä½•è¯­è¨€éƒ½å¯ä»¥è½»æ¾é›†æˆ
- **å®æ—¶è°ƒè¯•**: å‰ç«¯å®æ—¶æŸ¥çœ‹è°ƒç”¨è®°å½•
- **å¿«é€Ÿé‡æ”¾**: ä¿®æ”¹è¯·æ±‚å†…å®¹ç«‹å³æµ‹è¯•æ•ˆæœ
- **è½»é‡éƒ¨ç½²**: å•æ–‡ä»¶æ•°æ®åº“ï¼Œèµ„æºå ç”¨å°‘

## ğŸ¯ ä½¿ç”¨åœºæ™¯

- **Agentè°ƒè¯•**: å®æ—¶æŸ¥çœ‹Agentçš„å†³ç­–è¿‡ç¨‹
- **Promptä¼˜åŒ–**: å¿«é€Ÿæµ‹è¯•ä¸åŒçš„promptæ•ˆæœ
- **å‚æ•°è°ƒä¼˜**: å¯¹æ¯”ä¸åŒå‚æ•°çš„å“åº”ç»“æœ
- **é”™è¯¯æ’æŸ¥**: æŸ¥çœ‹å¤±è´¥çš„APIè°ƒç”¨è¯¦æƒ…
- **å¯¹è¯åˆ†æ**: åˆ†æå¤šè½®å¯¹è¯çš„ä¸Šä¸‹æ–‡
- **æ€§èƒ½ç›‘æ§**: ç›‘æ§LLMè°ƒç”¨çš„å“åº”æ—¶é—´

## ğŸ“ å¼€å‘è®¡åˆ’

- [x] åŸºç¡€æ¶æ„è®¾è®¡
- [ ] åç«¯APIå®ç°
- [ ] æ•°æ®åº“æ“ä½œ
- [ ] å‰ç«¯ç•Œé¢å¼€å‘
- [ ] é‡æ”¾åŠŸèƒ½å®ç°
- [ ] æ–‡æ¡£å®Œå–„
